{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jatins13/IMDb-sentiment-analysis/blob/main/Project_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LSZS5aKSiOS"
      },
      "source": [
        "import urllib.request as req\n",
        "import tarfile\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "imdb_url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "save_filename = \"aclImdb_v1.tar.gz\"\n",
        "if not os.path.exists(save_filename):\n",
        "    req.urlretrieve(imdb_url, save_filename)\n",
        "    \n",
        "imdb_folder = \"aclImdb\"\n",
        "if not os.path.exists(imdb_folder):\n",
        "    with tarfile.open(save_filename) as tar:\n",
        "        tar.extractall()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhrkTx2vSxQM"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def get_reviews(data_folder=\"/train\"):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    train_values = np.array([0,0])\n",
        "    test_values = np.array([0,0])\n",
        "    for index,sentiment in enumerate([\"/neg/\", \"/pos/\"]):\n",
        "        path = imdb_folder + data_folder + sentiment\n",
        "        path_test = imdb_folder + \"/test\" + sentiment\n",
        "        for filename in sorted(os.listdir(path)):\n",
        "            with open(path + filename, 'r') as f:\n",
        "                review = f.read()\n",
        "                review = review.lower()\n",
        "                review = review.replace(\"<br />\", \" \")\n",
        "                review = re.sub(r\"[^a-z ]\", \" \", review)\n",
        "                review = re.sub(r\" +\", \" \", review)\n",
        "                review = review.split(\" \")\n",
        "                reviews.append(review)\n",
        "                \n",
        "                label = [0, 0]\n",
        "                label[index] = 1\n",
        "                labels.append(label)\n",
        "        list = os.listdir(path) # dir is your directory path\n",
        "        number_files = len(list)\n",
        "        train_values[index] = number_files\n",
        "\n",
        "        list = os.listdir(path_test)\n",
        "        number_files = len(list)\n",
        "        test_values[index] = number_files\n",
        "\n",
        "    return reviews, np.array(labels), train_values, test_values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddsv-SUGTD5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "4b69e178-5f14-4923-ed15-a71e7aedbefb"
      },
      "source": [
        "train_reviews, train_labels, train_values,test_values = get_reviews()\n",
        "print(len(train_reviews))\n",
        "print(train_reviews[0])\n",
        "print(train_labels[0])\n",
        "bars = ('Negative','Positive')\n",
        "y_pos = np.arange(len(bars))\n",
        "plt.bar(y_pos,train_values)\n",
        "plt.xticks(y_pos,bars)\n",
        "plt.title('Training Set')\n",
        "plt.show()\n",
        "plt.bar(y_pos,test_values)\n",
        "plt.xticks(y_pos,bars)\n",
        "plt.title('Test Set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "['story', 'of', 'a', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'a', 'pig', 'starts', 'out', 'with', 'a', 'opening', 'scene', 'that', 'is', 'a', 'terrific', 'example', 'of', 'absurd', 'comedy', 'a', 'formal', 'orchestra', 'audience', 'is', 'turned', 'into', 'an', 'insane', 'violent', 'mob', 'by', 'the', 'crazy', 'chantings', 'of', 'it', 's', 'singers', 'unfortunately', 'it', 'stays', 'absurd', 'the', 'whole', 'time', 'with', 'no', 'general', 'narrative', 'eventually', 'making', 'it', 'just', 'too', 'off', 'putting', 'even', 'those', 'from', 'the', 'era', 'should', 'be', 'turned', 'off', 'the', 'cryptic', 'dialogue', 'would', 'make', 'shakespeare', 'seem', 'easy', 'to', 'a', 'third', 'grader', 'on', 'a', 'technical', 'level', 'it', 's', 'better', 'than', 'you', 'might', 'think', 'with', 'some', 'good', 'cinematography', 'by', 'future', 'great', 'vilmos', 'zsigmond', 'future', 'stars', 'sally', 'kirkland', 'and', 'frederic', 'forrest', 'can', 'be', 'seen', 'briefly', '']\n",
            "[1 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn1whGe_TIY7"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "\n",
        "save_filename = \"glove.6B.zip\"\n",
        "if not os.path.exists(save_filename):\n",
        "    req.urlretrieve(glove_url, save_filename)\n",
        "    \n",
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "glove_filename = \"glove.6B.{}d.txt\".format(EMBEDDING_SIZE)\n",
        "if not os.path.exists(glove_filename) and EMBEDDING_SIZE in [50,100,200,300]:\n",
        "    with zipfile.ZipFile(save_filename, 'r') as z:\n",
        "        z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcH-jnAEUwBm"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def load_embeddings():\n",
        "    with open(glove_filename, 'r') as glove_vectors:\n",
        "        word_to_int = defaultdict(int)\n",
        "        int_to_vec = defaultdict(lambda: np.zeros([EMBEDDING_SIZE]))\n",
        "        \n",
        "        index = 1\n",
        "        for line in glove_vectors:\n",
        "            fields = line.split()\n",
        "            word = str(fields[0])\n",
        "            vec = np.asarray(fields[1:], np.float32)\n",
        "            word_to_int[word] = index\n",
        "            int_to_vec[index] = vec\n",
        "            index += 1\n",
        "    return word_to_int, int_to_vec\n",
        "\n",
        "word_to_int, int_to_vec = load_embeddings()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-xhawrkU7oU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ae935f37-60c0-4cb1-a8a7-48678bff2b63"
      },
      "source": [
        "def review_words_to_ints(train_reviews):\n",
        "    train_data = []\n",
        "    for review in train_reviews:\n",
        "        int_review = [word_to_int[word] for word in review]\n",
        "        train_data.append(int_review)\n",
        "    return train_data\n",
        "\n",
        "train_reviews = review_words_to_ints(train_reviews)\n",
        "print(train_reviews[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[524, 4, 8, 301, 39, 32, 28639, 5045, 11, 8, 9611, 2384, 67, 18, 8, 876, 1501, 13, 15, 8, 11026, 881, 4, 12414, 2842, 8, 2725, 4079, 2053, 15, 853, 76, 30, 14917, 2529, 7632, 22, 1, 5579, 0, 4, 21, 1535, 7793, 4717, 21, 7888, 12414, 1, 1116, 80, 18, 85, 217, 8040, 1182, 434, 21, 121, 318, 139, 2221, 152, 156, 26, 1, 1593, 190, 31, 853, 139, 1, 29298, 2470, 55, 160, 7478, 1915, 1674, 5, 8, 246, 20156, 14, 8, 2027, 506, 21, 1535, 440, 74, 82, 415, 270, 18, 78, 220, 22182, 22, 582, 354, 107311, 127384, 582, 1570, 10946, 23761, 6, 15679, 16084, 87, 31, 542, 3443, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvg5__JaVEbp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "7f792bd8-0a21-4bef-9eac-eb38605bd9e2"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "train_reviews_lens = [len(review) for review in train_reviews]\n",
        "sns.distplot(train_reviews_lens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0c8cf814e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsGWY0-TVTBy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cb3617eb-810d-40fd-cfa3-86b7e85d5e87"
      },
      "source": [
        "MAX_REVIEW_LEN = 500\n",
        "\n",
        "def zero_pad_reviews(train_reviews):\n",
        "    train_data_padded = []\n",
        "    for review in train_reviews:\n",
        "        padded = [0] * MAX_REVIEW_LEN\n",
        "        stop_index = min(len(review), MAX_REVIEW_LEN)\n",
        "        padded[:stop_index] = review[:stop_index]\n",
        "        train_data_padded.append(padded)\n",
        "    return train_data_padded\n",
        "\n",
        "train_reviews = zero_pad_reviews(train_reviews)\n",
        "print(train_reviews[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[524, 4, 8, 301, 39, 32, 28639, 5045, 11, 8, 9611, 2384, 67, 18, 8, 876, 1501, 13, 15, 8, 11026, 881, 4, 12414, 2842, 8, 2725, 4079, 2053, 15, 853, 76, 30, 14917, 2529, 7632, 22, 1, 5579, 0, 4, 21, 1535, 7793, 4717, 21, 7888, 12414, 1, 1116, 80, 18, 85, 217, 8040, 1182, 434, 21, 121, 318, 139, 2221, 152, 156, 26, 1, 1593, 190, 31, 853, 139, 1, 29298, 2470, 55, 160, 7478, 1915, 1674, 5, 8, 246, 20156, 14, 8, 2027, 506, 21, 1535, 440, 74, 82, 415, 270, 18, 78, 220, 22182, 22, 582, 354, 107311, 127384, 582, 1570, 10946, 23761, 6, 15679, 16084, 87, 31, 542, 3443, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8rfZejfVw9L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40cfcaa6-beac-4c25-9ed7-35dc8b0ac2c1"
      },
      "source": [
        "def review_ints_to_vecs(train_reviews):\n",
        "    train_data = []\n",
        "    for review in train_reviews:\n",
        "        vec_review = [int_to_vec[word] for word in review]\n",
        "        train_data.append(vec_review)\n",
        "    return train_data\n",
        "\n",
        "train_reviews = np.array(review_ints_to_vecs(train_reviews))\n",
        "print(train_reviews.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 500, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6JY0A_OV_NG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ee28632-d867-46e8-e57c-d71c74883a43"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "def define_graph():\n",
        "    OUTPUT_SIZE = 2\n",
        "    \n",
        "    X = tf.placeholder(tf.float32, [None, MAX_REVIEW_LEN, EMBEDDING_SIZE])\n",
        "    Y = tf.placeholder(tf.int32, [None, OUTPUT_SIZE])\n",
        "    keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
        "    \n",
        "    rnn = tf.contrib.rnn.GRUCell(125, activation=tf.nn.relu)\n",
        "    drop0 = tf.contrib.rnn.DropoutWrapper(rnn, output_keep_prob=keep_prob)\n",
        "    outputs, final = tf.nn.dynamic_rnn(drop0, X, dtype=tf.float32)\n",
        "    dense = tf.layers.dense(outputs[:,-1], 100, activation=tf.nn.relu)\n",
        "    drop1 = tf.layers.dropout(dense, rate=(1-keep_prob))\n",
        "    logits = tf.layers.dense(drop1, OUTPUT_SIZE, activation=None)\n",
        "    \n",
        "    error = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n",
        "    loss = tf.reduce_sum(error)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
        "    \n",
        "    preds = tf.nn.softmax(logits)\n",
        "    correct = tf.equal(tf.argmax(preds, axis=1), tf.argmax(Y, axis=1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "    \n",
        "    return X, Y, keep_prob, optimizer, loss, accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfqNMw5RWCGa"
      },
      "source": [
        "permutation = [(i//2)+12500*(i%2) for i in range(len(train_reviews))]\n",
        "train_reviews = train_reviews[permutation]\n",
        "train_labels = train_labels[permutation]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY0UMPWFWuke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0363b8dd-222d-4edb-9bb5-d95310ea1731"
      },
      "source": [
        "\n",
        "validation_size = 1000\n",
        "train_size = len(train_reviews) - validation_size\n",
        "\n",
        "x_train = train_reviews[:train_size]\n",
        "y_train = train_labels[:train_size]\n",
        "x_val = train_reviews[train_size:]\n",
        "y_val = train_labels[train_size:]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24000, 500, 50)\n",
            "(24000, 2)\n",
            "(1000, 500, 50)\n",
            "(1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlnxoMa6Ww5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3e597c2-662d-4628-9619-4b6959045332"
      },
      "source": [
        "BATCH_SIZE = 50\n",
        "\n",
        "num_samples = len(x_train)\n",
        "num_batches = int(num_samples//BATCH_SIZE)\n",
        "\n",
        "accT = []\n",
        "accV = []\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "\n",
        "X, Y, keep_prob, optimizer, loss, accuracy = define_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for epoch in range(10):\n",
        "        for i in range(0, num_samples, BATCH_SIZE):\n",
        "            x_train_batch = x_train[i:i+BATCH_SIZE]\n",
        "            y_train_batch = y_train[i:i+BATCH_SIZE]\n",
        "            \n",
        "            _, train_loss, train_acc = sess.run([optimizer, loss, accuracy],\n",
        "                                               feed_dict={X:x_train_batch, Y:y_train_batch, keep_prob:0.5})\n",
        "            \n",
        "            if (i%1000) == 0:\n",
        "                val_acc = sess.run(accuracy, feed_dict={X:x_val, Y:y_val})\n",
        "                print(\"Epoch {0}:{1:2d}, Train loss: {2:2.2f}, Train acc: {3:.3f}, Val acc: {4:.3f}\"\n",
        "                     .format(epoch, i//1000, train_loss, train_acc, val_acc))\n",
        "                accT.append(train_acc)\n",
        "                accV.append(val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-10-1c6893101118>:11: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-10-1c6893101118>:13: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-10-1c6893101118>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-1c6893101118>:15: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "Epoch 0: 0, Train loss: 34.84, Train acc: 0.480, Val acc: 0.501\n",
            "Epoch 0: 1, Train loss: 34.21, Train acc: 0.580, Val acc: 0.506\n",
            "Epoch 0: 2, Train loss: 34.63, Train acc: 0.520, Val acc: 0.507\n",
            "Epoch 0: 3, Train loss: 34.00, Train acc: 0.560, Val acc: 0.506\n",
            "Epoch 0: 4, Train loss: 35.14, Train acc: 0.520, Val acc: 0.508\n",
            "Epoch 0: 5, Train loss: 34.44, Train acc: 0.540, Val acc: 0.499\n",
            "Epoch 0: 6, Train loss: 34.12, Train acc: 0.480, Val acc: 0.500\n",
            "Epoch 0: 7, Train loss: 34.16, Train acc: 0.540, Val acc: 0.509\n",
            "Epoch 0: 8, Train loss: 34.83, Train acc: 0.500, Val acc: 0.504\n",
            "Epoch 0: 9, Train loss: 34.53, Train acc: 0.720, Val acc: 0.498\n",
            "Epoch 0:10, Train loss: 34.51, Train acc: 0.580, Val acc: 0.504\n",
            "Epoch 0:11, Train loss: 34.52, Train acc: 0.560, Val acc: 0.504\n",
            "Epoch 0:12, Train loss: 33.79, Train acc: 0.640, Val acc: 0.506\n",
            "Epoch 0:13, Train loss: 34.88, Train acc: 0.480, Val acc: 0.498\n",
            "Epoch 0:14, Train loss: 34.46, Train acc: 0.480, Val acc: 0.497\n",
            "Epoch 0:15, Train loss: 34.43, Train acc: 0.540, Val acc: 0.509\n",
            "Epoch 0:16, Train loss: 35.11, Train acc: 0.520, Val acc: 0.508\n",
            "Epoch 0:17, Train loss: 34.31, Train acc: 0.640, Val acc: 0.501\n",
            "Epoch 0:18, Train loss: 34.06, Train acc: 0.540, Val acc: 0.500\n",
            "Epoch 0:19, Train loss: 34.10, Train acc: 0.540, Val acc: 0.508\n",
            "Epoch 0:20, Train loss: 34.58, Train acc: 0.520, Val acc: 0.502\n",
            "Epoch 0:21, Train loss: 35.17, Train acc: 0.480, Val acc: 0.497\n",
            "Epoch 0:22, Train loss: 34.49, Train acc: 0.620, Val acc: 0.507\n",
            "Epoch 0:23, Train loss: 34.71, Train acc: 0.500, Val acc: 0.505\n",
            "Epoch 1: 0, Train loss: 34.76, Train acc: 0.460, Val acc: 0.505\n",
            "Epoch 1: 1, Train loss: 34.36, Train acc: 0.520, Val acc: 0.507\n",
            "Epoch 1: 2, Train loss: 34.42, Train acc: 0.520, Val acc: 0.503\n",
            "Epoch 1: 3, Train loss: 34.00, Train acc: 0.620, Val acc: 0.505\n",
            "Epoch 1: 4, Train loss: 35.19, Train acc: 0.500, Val acc: 0.505\n",
            "Epoch 1: 5, Train loss: 34.71, Train acc: 0.540, Val acc: 0.502\n",
            "Epoch 1: 6, Train loss: 33.69, Train acc: 0.700, Val acc: 0.512\n",
            "Epoch 1: 7, Train loss: 34.53, Train acc: 0.520, Val acc: 0.500\n",
            "Epoch 1: 8, Train loss: 34.65, Train acc: 0.440, Val acc: 0.511\n",
            "Epoch 1: 9, Train loss: 34.45, Train acc: 0.500, Val acc: 0.502\n",
            "Epoch 1:10, Train loss: 34.58, Train acc: 0.460, Val acc: 0.508\n",
            "Epoch 1:11, Train loss: 34.33, Train acc: 0.520, Val acc: 0.507\n",
            "Epoch 1:12, Train loss: 33.82, Train acc: 0.560, Val acc: 0.509\n",
            "Epoch 1:13, Train loss: 190.41, Train acc: 0.620, Val acc: 0.507\n",
            "Epoch 1:14, Train loss: 34.89, Train acc: 0.500, Val acc: 0.500\n",
            "Epoch 1:15, Train loss: 33.97, Train acc: 0.600, Val acc: 0.506\n",
            "Epoch 1:16, Train loss: 34.90, Train acc: 0.480, Val acc: 0.506\n",
            "Epoch 1:17, Train loss: 34.72, Train acc: 0.480, Val acc: 0.510\n",
            "Epoch 1:18, Train loss: 34.19, Train acc: 0.520, Val acc: 0.504\n",
            "Epoch 1:19, Train loss: 34.66, Train acc: 0.480, Val acc: 0.507\n",
            "Epoch 1:20, Train loss: 34.32, Train acc: 0.540, Val acc: 0.510\n",
            "Epoch 1:21, Train loss: 34.21, Train acc: 0.640, Val acc: 0.510\n",
            "Epoch 1:22, Train loss: 34.17, Train acc: 0.600, Val acc: 0.504\n",
            "Epoch 1:23, Train loss: 34.74, Train acc: 0.480, Val acc: 0.507\n",
            "Epoch 2: 0, Train loss: 34.98, Train acc: 0.500, Val acc: 0.506\n",
            "Epoch 2: 1, Train loss: 34.54, Train acc: 0.520, Val acc: 0.508\n",
            "Epoch 2: 2, Train loss: 34.53, Train acc: 0.520, Val acc: 0.506\n",
            "Epoch 2: 3, Train loss: 34.36, Train acc: 0.540, Val acc: 0.506\n",
            "Epoch 2: 4, Train loss: 34.73, Train acc: 0.500, Val acc: 0.507\n",
            "Epoch 2: 5, Train loss: 34.67, Train acc: 0.500, Val acc: 0.509\n",
            "Epoch 2: 6, Train loss: 34.15, Train acc: 0.520, Val acc: 0.507\n",
            "Epoch 2: 7, Train loss: 33.95, Train acc: 0.520, Val acc: 0.503\n",
            "Epoch 2: 8, Train loss: 34.41, Train acc: 0.520, Val acc: 0.500\n",
            "Epoch 2: 9, Train loss: 34.50, Train acc: 0.660, Val acc: 0.505\n",
            "Epoch 2:10, Train loss: 35.09, Train acc: 0.600, Val acc: 0.511\n",
            "Epoch 2:11, Train loss: 34.09, Train acc: 0.620, Val acc: 0.507\n",
            "Epoch 2:12, Train loss: 33.69, Train acc: 0.520, Val acc: 0.507\n",
            "Epoch 2:13, Train loss: 34.70, Train acc: 0.480, Val acc: 0.506\n",
            "Epoch 2:14, Train loss: 34.86, Train acc: 0.500, Val acc: 0.499\n",
            "Epoch 2:15, Train loss: 34.38, Train acc: 0.600, Val acc: 0.505\n",
            "Epoch 2:16, Train loss: 34.79, Train acc: 0.500, Val acc: 0.510\n",
            "Epoch 2:17, Train loss: 34.47, Train acc: 0.500, Val acc: 0.507\n",
            "Epoch 2:18, Train loss: 34.21, Train acc: 0.520, Val acc: 0.510\n",
            "Epoch 2:19, Train loss: 35.06, Train acc: 0.500, Val acc: 0.508\n",
            "Epoch 2:20, Train loss: 34.22, Train acc: 0.560, Val acc: 0.509\n",
            "Epoch 2:21, Train loss: 32.11, Train acc: 0.540, Val acc: 0.499\n",
            "Epoch 2:22, Train loss: 34.25, Train acc: 0.560, Val acc: 0.507\n",
            "Epoch 2:23, Train loss: 34.48, Train acc: 0.500, Val acc: 0.509\n",
            "Epoch 3: 0, Train loss: 34.44, Train acc: 0.540, Val acc: 0.513\n",
            "Epoch 3: 1, Train loss: 34.23, Train acc: 0.540, Val acc: 0.513\n",
            "Epoch 3: 2, Train loss: 34.05, Train acc: 0.500, Val acc: 0.511\n",
            "Epoch 3: 3, Train loss: 33.44, Train acc: 0.540, Val acc: 0.514\n",
            "Epoch 3: 4, Train loss: 36.28, Train acc: 0.500, Val acc: 0.501\n",
            "Epoch 3: 5, Train loss: 34.13, Train acc: 0.500, Val acc: 0.500\n",
            "Epoch 3: 6, Train loss: 34.15, Train acc: 0.540, Val acc: 0.495\n",
            "Epoch 3: 7, Train loss: 34.50, Train acc: 0.520, Val acc: 0.495\n",
            "Epoch 3: 8, Train loss: 34.34, Train acc: 0.500, Val acc: 0.497\n",
            "Epoch 3: 9, Train loss: 34.73, Train acc: 0.520, Val acc: 0.498\n",
            "Epoch 3:10, Train loss: 34.64, Train acc: 0.520, Val acc: 0.499\n",
            "Epoch 3:11, Train loss: 34.77, Train acc: 0.540, Val acc: 0.500\n",
            "Epoch 3:12, Train loss: 33.84, Train acc: 0.540, Val acc: 0.505\n",
            "Epoch 3:13, Train loss: 33.86, Train acc: 0.620, Val acc: 0.498\n",
            "Epoch 3:14, Train loss: 34.34, Train acc: 0.500, Val acc: 0.500\n",
            "Epoch 3:15, Train loss: 34.17, Train acc: 0.500, Val acc: 0.504\n",
            "Epoch 3:16, Train loss: 34.51, Train acc: 0.520, Val acc: 0.511\n",
            "Epoch 3:17, Train loss: 34.68, Train acc: 0.500, Val acc: 0.505\n",
            "Epoch 3:18, Train loss: 33.95, Train acc: 0.520, Val acc: 0.504\n",
            "Epoch 3:19, Train loss: 33.80, Train acc: 0.560, Val acc: 0.512\n",
            "Epoch 3:20, Train loss: 33.99, Train acc: 0.540, Val acc: 0.509\n",
            "Epoch 3:21, Train loss: 33.75, Train acc: 0.620, Val acc: 0.501\n",
            "Epoch 3:22, Train loss: 34.86, Train acc: 0.380, Val acc: 0.504\n",
            "Epoch 3:23, Train loss: 34.58, Train acc: 0.420, Val acc: 0.507\n",
            "Epoch 4: 0, Train loss: 34.93, Train acc: 0.460, Val acc: 0.510\n",
            "Epoch 4: 1, Train loss: 33.54, Train acc: 0.620, Val acc: 0.511\n",
            "Epoch 4: 2, Train loss: 34.12, Train acc: 0.500, Val acc: 0.511\n",
            "Epoch 4: 3, Train loss: 33.33, Train acc: 0.580, Val acc: 0.517\n",
            "Epoch 4: 4, Train loss: 35.50, Train acc: 0.520, Val acc: 0.508\n",
            "Epoch 4: 5, Train loss: 33.46, Train acc: 0.560, Val acc: 0.507\n",
            "Epoch 4: 6, Train loss: 34.43, Train acc: 0.520, Val acc: 0.504\n",
            "Epoch 4: 7, Train loss: 63.88, Train acc: 0.580, Val acc: 0.518\n",
            "Epoch 4: 8, Train loss: 33.53, Train acc: 0.540, Val acc: 0.508\n",
            "Epoch 4: 9, Train loss: 34.20, Train acc: 0.480, Val acc: 0.500\n",
            "Epoch 4:10, Train loss: 34.69, Train acc: 0.560, Val acc: 0.505\n",
            "Epoch 4:11, Train loss: 34.11, Train acc: 0.540, Val acc: 0.507\n",
            "Epoch 4:12, Train loss: 32.41, Train acc: 0.520, Val acc: 0.503\n",
            "Epoch 4:13, Train loss: 34.11, Train acc: 0.520, Val acc: 0.510\n",
            "Epoch 4:14, Train loss: 34.39, Train acc: 0.520, Val acc: 0.503\n",
            "Epoch 4:15, Train loss: 34.92, Train acc: 0.540, Val acc: 0.506\n",
            "Epoch 4:16, Train loss: 34.52, Train acc: 0.460, Val acc: 0.502\n",
            "Epoch 4:17, Train loss: 34.49, Train acc: 0.500, Val acc: 0.502\n",
            "Epoch 4:18, Train loss: 34.76, Train acc: 0.380, Val acc: 0.501\n",
            "Epoch 4:19, Train loss: 34.34, Train acc: 0.500, Val acc: 0.511\n",
            "Epoch 4:20, Train loss: 34.20, Train acc: 0.500, Val acc: 0.506\n",
            "Epoch 4:21, Train loss: 33.66, Train acc: 0.520, Val acc: 0.504\n",
            "Epoch 4:22, Train loss: 35.56, Train acc: 0.380, Val acc: 0.502\n",
            "Epoch 4:23, Train loss: 34.70, Train acc: 0.520, Val acc: 0.499\n",
            "Epoch 5: 0, Train loss: 34.62, Train acc: 0.420, Val acc: 0.506\n",
            "Epoch 5: 1, Train loss: 33.75, Train acc: 0.520, Val acc: 0.505\n",
            "Epoch 5: 2, Train loss: 34.23, Train acc: 0.520, Val acc: 0.506\n",
            "Epoch 5: 3, Train loss: 34.22, Train acc: 0.540, Val acc: 0.509\n",
            "Epoch 5: 4, Train loss: 35.12, Train acc: 0.500, Val acc: 0.509\n",
            "Epoch 5: 5, Train loss: 33.37, Train acc: 0.560, Val acc: 0.504\n",
            "Epoch 5: 6, Train loss: 33.65, Train acc: 0.520, Val acc: 0.504\n",
            "Epoch 5: 7, Train loss: 33.77, Train acc: 0.420, Val acc: 0.512\n",
            "Epoch 5: 8, Train loss: 33.90, Train acc: 0.520, Val acc: 0.507\n",
            "Epoch 5: 9, Train loss: 34.89, Train acc: 0.520, Val acc: 0.509\n",
            "Epoch 5:10, Train loss: 34.37, Train acc: 0.520, Val acc: 0.502\n",
            "Epoch 5:11, Train loss: 34.71, Train acc: 0.520, Val acc: 0.503\n",
            "Epoch 5:12, Train loss: 33.86, Train acc: 0.500, Val acc: 0.509\n",
            "Epoch 5:13, Train loss: 33.48, Train acc: 0.540, Val acc: 0.504\n",
            "Epoch 5:14, Train loss: 33.88, Train acc: 0.520, Val acc: 0.510\n",
            "Epoch 5:15, Train loss: 33.52, Train acc: 0.500, Val acc: 0.509\n",
            "Epoch 5:16, Train loss: 34.47, Train acc: 0.500, Val acc: 0.504\n",
            "Epoch 5:17, Train loss: 34.33, Train acc: 0.540, Val acc: 0.508\n",
            "Epoch 5:18, Train loss: 33.36, Train acc: 0.600, Val acc: 0.510\n",
            "Epoch 5:19, Train loss: 32.01, Train acc: 0.580, Val acc: 0.558\n",
            "Epoch 5:20, Train loss: 32.76, Train acc: 0.600, Val acc: 0.533\n",
            "Epoch 5:21, Train loss: 29.19, Train acc: 0.720, Val acc: 0.681\n",
            "Epoch 5:22, Train loss: 29.31, Train acc: 0.660, Val acc: 0.597\n",
            "Epoch 5:23, Train loss: 25.57, Train acc: 0.860, Val acc: 0.707\n",
            "Epoch 6: 0, Train loss: 37.26, Train acc: 0.600, Val acc: 0.698\n",
            "Epoch 6: 1, Train loss: 34.64, Train acc: 0.600, Val acc: 0.578\n",
            "Epoch 6: 2, Train loss: 28.55, Train acc: 0.740, Val acc: 0.692\n",
            "Epoch 6: 3, Train loss: 24.58, Train acc: 0.840, Val acc: 0.742\n",
            "Epoch 6: 4, Train loss: 29.00, Train acc: 0.780, Val acc: 0.713\n",
            "Epoch 6: 5, Train loss: 21.86, Train acc: 0.840, Val acc: 0.708\n",
            "Epoch 6: 6, Train loss: 26.19, Train acc: 0.740, Val acc: 0.732\n",
            "Epoch 6: 7, Train loss: 26.25, Train acc: 0.760, Val acc: 0.716\n",
            "Epoch 6: 8, Train loss: 29.40, Train acc: 0.660, Val acc: 0.548\n",
            "Epoch 6: 9, Train loss: 26.86, Train acc: 0.700, Val acc: 0.718\n",
            "Epoch 6:10, Train loss: 30.11, Train acc: 0.740, Val acc: 0.732\n",
            "Epoch 6:11, Train loss: 29.58, Train acc: 0.680, Val acc: 0.738\n",
            "Epoch 6:12, Train loss: 27.90, Train acc: 0.800, Val acc: 0.734\n",
            "Epoch 6:13, Train loss: 27.17, Train acc: 0.740, Val acc: 0.749\n",
            "Epoch 6:14, Train loss: 19.51, Train acc: 0.840, Val acc: 0.743\n",
            "Epoch 6:15, Train loss: 28.62, Train acc: 0.740, Val acc: 0.741\n",
            "Epoch 6:16, Train loss: 28.20, Train acc: 0.780, Val acc: 0.756\n",
            "Epoch 6:17, Train loss: 23.24, Train acc: 0.820, Val acc: 0.759\n",
            "Epoch 6:18, Train loss: 20.69, Train acc: 0.860, Val acc: 0.751\n",
            "Epoch 6:19, Train loss: 30.45, Train acc: 0.620, Val acc: 0.713\n",
            "Epoch 6:20, Train loss: 22.50, Train acc: 0.820, Val acc: 0.737\n",
            "Epoch 6:21, Train loss: 30.39, Train acc: 0.680, Val acc: 0.729\n",
            "Epoch 6:22, Train loss: 34.03, Train acc: 0.580, Val acc: 0.739\n",
            "Epoch 6:23, Train loss: 14.97, Train acc: 0.900, Val acc: 0.755\n",
            "Epoch 7: 0, Train loss: 29.62, Train acc: 0.660, Val acc: 0.748\n",
            "Epoch 7: 1, Train loss: 21.95, Train acc: 0.840, Val acc: 0.764\n",
            "Epoch 7: 2, Train loss: 30.24, Train acc: 0.720, Val acc: 0.635\n",
            "Epoch 7: 3, Train loss: 29.38, Train acc: 0.800, Val acc: 0.706\n",
            "Epoch 7: 4, Train loss: 27.11, Train acc: 0.800, Val acc: 0.731\n",
            "Epoch 7: 5, Train loss: 20.99, Train acc: 0.880, Val acc: 0.747\n",
            "Epoch 7: 6, Train loss: 28.20, Train acc: 0.740, Val acc: 0.768\n",
            "Epoch 7: 7, Train loss: 22.26, Train acc: 0.780, Val acc: 0.770\n",
            "Epoch 7: 8, Train loss: 26.46, Train acc: 0.720, Val acc: 0.767\n",
            "Epoch 7: 9, Train loss: 24.96, Train acc: 0.760, Val acc: 0.770\n",
            "Epoch 7:10, Train loss: 24.67, Train acc: 0.760, Val acc: 0.776\n",
            "Epoch 7:11, Train loss: 25.68, Train acc: 0.700, Val acc: 0.776\n",
            "Epoch 7:12, Train loss: 18.07, Train acc: 0.880, Val acc: 0.780\n",
            "Epoch 7:13, Train loss: 24.84, Train acc: 0.720, Val acc: 0.781\n",
            "Epoch 7:14, Train loss: 16.88, Train acc: 0.880, Val acc: 0.777\n",
            "Epoch 7:15, Train loss: 24.89, Train acc: 0.740, Val acc: 0.782\n",
            "Epoch 7:16, Train loss: 27.88, Train acc: 0.760, Val acc: 0.784\n",
            "Epoch 7:17, Train loss: 15.62, Train acc: 0.860, Val acc: 0.787\n",
            "Epoch 7:18, Train loss: 18.95, Train acc: 0.800, Val acc: 0.792\n",
            "Epoch 7:19, Train loss: 16.58, Train acc: 0.800, Val acc: 0.788\n",
            "Epoch 7:20, Train loss: 11.92, Train acc: 0.940, Val acc: 0.795\n",
            "Epoch 7:21, Train loss: 25.34, Train acc: 0.760, Val acc: 0.789\n",
            "Epoch 7:22, Train loss: 27.80, Train acc: 0.720, Val acc: 0.792\n",
            "Epoch 7:23, Train loss: 13.72, Train acc: 0.900, Val acc: 0.793\n",
            "Epoch 8: 0, Train loss: 25.26, Train acc: 0.740, Val acc: 0.796\n",
            "Epoch 8: 1, Train loss: 18.76, Train acc: 0.840, Val acc: 0.800\n",
            "Epoch 8: 2, Train loss: 17.55, Train acc: 0.920, Val acc: 0.778\n",
            "Epoch 8: 3, Train loss: 22.98, Train acc: 0.760, Val acc: 0.789\n",
            "Epoch 8: 4, Train loss: 19.55, Train acc: 0.820, Val acc: 0.781\n",
            "Epoch 8: 5, Train loss: 15.72, Train acc: 0.880, Val acc: 0.800\n",
            "Epoch 8: 6, Train loss: 25.77, Train acc: 0.700, Val acc: 0.797\n",
            "Epoch 8: 7, Train loss: 15.53, Train acc: 0.820, Val acc: 0.803\n",
            "Epoch 8: 8, Train loss: 21.38, Train acc: 0.780, Val acc: 0.805\n",
            "Epoch 8: 9, Train loss: 18.10, Train acc: 0.880, Val acc: 0.806\n",
            "Epoch 8:10, Train loss: 20.88, Train acc: 0.860, Val acc: 0.804\n",
            "Epoch 8:11, Train loss: 27.42, Train acc: 0.740, Val acc: 0.809\n",
            "Epoch 8:12, Train loss: 18.07, Train acc: 0.860, Val acc: 0.804\n",
            "Epoch 8:13, Train loss: 20.89, Train acc: 0.820, Val acc: 0.803\n",
            "Epoch 8:14, Train loss: 15.99, Train acc: 0.880, Val acc: 0.803\n",
            "Epoch 8:15, Train loss: 24.90, Train acc: 0.740, Val acc: 0.806\n",
            "Epoch 8:16, Train loss: 24.52, Train acc: 0.820, Val acc: 0.798\n",
            "Epoch 8:17, Train loss: 14.04, Train acc: 0.900, Val acc: 0.804\n",
            "Epoch 8:18, Train loss: 18.17, Train acc: 0.800, Val acc: 0.807\n",
            "Epoch 8:19, Train loss: 15.05, Train acc: 0.860, Val acc: 0.806\n",
            "Epoch 8:20, Train loss: 12.32, Train acc: 0.960, Val acc: 0.806\n",
            "Epoch 8:21, Train loss: 22.92, Train acc: 0.760, Val acc: 0.810\n",
            "Epoch 8:22, Train loss: 24.60, Train acc: 0.760, Val acc: 0.812\n",
            "Epoch 8:23, Train loss: 9.50, Train acc: 0.940, Val acc: 0.809\n",
            "Epoch 9: 0, Train loss: 23.38, Train acc: 0.760, Val acc: 0.821\n",
            "Epoch 9: 1, Train loss: 16.73, Train acc: 0.840, Val acc: 0.807\n",
            "Epoch 9: 2, Train loss: 14.68, Train acc: 0.860, Val acc: 0.810\n",
            "Epoch 9: 3, Train loss: 14.34, Train acc: 0.860, Val acc: 0.812\n",
            "Epoch 9: 4, Train loss: 12.56, Train acc: 0.880, Val acc: 0.824\n",
            "Epoch 9: 5, Train loss: 17.70, Train acc: 0.860, Val acc: 0.819\n",
            "Epoch 9: 6, Train loss: 24.52, Train acc: 0.680, Val acc: 0.824\n",
            "Epoch 9: 7, Train loss: 13.99, Train acc: 0.920, Val acc: 0.816\n",
            "Epoch 9: 8, Train loss: 17.55, Train acc: 0.820, Val acc: 0.819\n",
            "Epoch 9: 9, Train loss: 15.45, Train acc: 0.880, Val acc: 0.812\n",
            "Epoch 9:10, Train loss: 23.07, Train acc: 0.800, Val acc: 0.810\n",
            "Epoch 9:11, Train loss: 24.05, Train acc: 0.780, Val acc: 0.822\n",
            "Epoch 9:12, Train loss: 14.46, Train acc: 0.880, Val acc: 0.819\n",
            "Epoch 9:13, Train loss: 18.51, Train acc: 0.820, Val acc: 0.821\n",
            "Epoch 9:14, Train loss: 19.35, Train acc: 0.820, Val acc: 0.805\n",
            "Epoch 9:15, Train loss: 25.99, Train acc: 0.780, Val acc: 0.826\n",
            "Epoch 9:16, Train loss: 21.65, Train acc: 0.840, Val acc: 0.824\n",
            "Epoch 9:17, Train loss: 12.49, Train acc: 0.900, Val acc: 0.824\n",
            "Epoch 9:18, Train loss: 14.69, Train acc: 0.860, Val acc: 0.825\n",
            "Epoch 9:19, Train loss: 10.04, Train acc: 0.940, Val acc: 0.823\n",
            "Epoch 9:20, Train loss: 12.11, Train acc: 0.920, Val acc: 0.820\n",
            "Epoch 9:21, Train loss: 21.24, Train acc: 0.780, Val acc: 0.820\n",
            "Epoch 9:22, Train loss: 19.48, Train acc: 0.820, Val acc: 0.834\n",
            "Epoch 9:23, Train loss: 8.41, Train acc: 0.920, Val acc: 0.829\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}